---
title: Vietnamese NER Demo
emoji: ğŸ§ 
colorFrom: indigo
colorTo: yellow
sdk: streamlit
sdk_version: 1.46.1
app_file: src/app.py
pinned: false
---
# Vietnamese Named Entity Recognition (NER) ğŸ§ 

A comprehensive Vietnamese Named Entity Recognition system using state-of-the-art deep learning models including PhoBERT, CRF, and ensemble methods.


## ğŸš€ Live Demo

Try the interactive demo: **[Vietnamese NER Demo](https://huggingface.co/spaces/DucLai/Vietnamese_NER)**

![Demo Screenshot](https://github.com/user-attachments/assets/4fbcdc49-5a8b-47c0-991e-d3ec839cede9)

## ğŸ”„ Project Workflow

![Project Flowchart](https://github.com/user-attachments/assets/5b800180-d6c8-44f7-8622-ba188f6cd7be)

## ğŸ¯ Overview

This project implements a robust Vietnamese Named Entity Recognition system that can identify and classify entities in Vietnamese text. The system combines multiple approaches including:

- **PhoBERT-based embeddings** for contextual understanding
- **Conditional Random Fields (CRF)** for sequence labeling
- **Random Forest** with semantic embeddings
- **Rule-based methods** for enhanced accuracy

## ğŸ“‚ Project Structure

```
VIETNAMESE_NER/
â”‚
â”œâ”€â”€ .github/workflows              
â”‚   â””â”€â”€ main.yml                   # Auto deploy to Hugging Space
â”‚
â”œâ”€â”€ data/                          # Dataset files
â”‚   â””â”€â”€ raw_data.csv               # Raw training data
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ Duc_Notebook.ipynb         # CRF + RandomForest experiments
â”‚   â”œâ”€â”€ Softmax_PhoBERT.ipynb      # Softmax approach
â”‚   â”œâ”€â”€ Kien_Rule_base.ipynb       # Rule-based method with RF
â”‚   â””â”€â”€ Kien_RF_lightgbm.ipynb     # RF with semantic embeddings
â”‚
â”œâ”€â”€ src/                           # Main source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                     # Streamlit web application
â”‚   â”œâ”€â”€ front.py                   # Highlight function
â”‚   â”œâ”€â”€ config.py                  # Project configuration
â”‚   â”œâ”€â”€ data_loader.py             # Data loading utilities
â”‚   â”œâ”€â”€ preprocessing.py           # Data preprocessing functions
â”‚   â”œâ”€â”€ model.py                   # Model architecture definitions
â”‚   â”œâ”€â”€ train.py                   # Training pipeline
â”‚   â”œâ”€â”€ evaluate.py                # Model evaluation
â”‚   â””â”€â”€ predict.py                 # Inference utilities
â”‚
â”œâ”€â”€ models/                        # Saved model artifacts
â”‚   â””â”€â”€ best_model.pt              # Best trained model weights
â”‚
â”œâ”€â”€ outputs/                       # Training outputs
â”‚   â”œâ”€â”€ output.log                 # Training logs (TensorBoard)
â”‚   â””â”€â”€ figures/                   # Visualization plots
â”‚
â”œâ”€â”€ tests/                         # Unit tests (planned)
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ environment.yml                # Conda environment file
â”œâ”€â”€ README.md                      # Project documentation
â””â”€â”€ run.py                        # Main training script
```


## ğŸ—ï¸ Model Architecture

The system uses a hybrid architecture combining the strengths of different approaches:

![Model Architecture](https://github.com/user-attachments/assets/82d243a2-42fa-4dad-b1af-8946767d4f44)

### Core Components:
- **PhoBERT-Base**: Generates contextual embeddings for Vietnamese text
- **Linear + CRF Layer**: Handles sequence labeling with context awareness
- **Softmax/Random Forest**: Provides single-label prediction capabilities

## ğŸ“Š Dataset & Performance

### Dataset: VLSP2016
The model is trained on the VLSP2016 dataset extracted from Vietnamese news articles.

#### Dataset Statistics:
<table>
  <tr>
    <td><img src="https://github.com/user-attachments/assets/20116929-1556-44b2-86e9-086b72320f22" alt="Entity Frequency" width="600"/></td>
    <td><img src="https://github.com/user-attachments/assets/9cafb068-bbda-4ee1-9fc9-bd4edded1438" alt="Entity Distribution" width="600"/></td>
  </tr>
  <tr>
    <td><img src="https://github.com/user-attachments/assets/db9421c0-4e9c-4654-92d0-d924932384dc" alt="Token Length Distribution" width="600"/></td>
    <td><img src="https://github.com/user-attachments/assets/70871bc5-ccb4-4186-9538-ac479c771415" alt="Sentence Length Distribution" width="600"/></td>
  </tr>
</table>


### Model Performance:
<table>
  <tr>
    <td>
      <img src="https://github.com/user-attachments/assets/9fb24f3a-466c-46f1-94d2-bcb6f26abd72" alt="F1 Score" width="600"/>
    </td>
    <td>
      <img src="https://github.com/user-attachments/assets/11b8080a-38d6-4ea2-b350-21361345fd1e" alt="Training Loss" width="600"/>
    </td>
  </tr>
</table>

![Results Comparison](https://github.com/user-attachments/assets/e2fecc2c-8b27-4f28-a174-41078b17567c)

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.10+
- Conda (recommended)

### Option 1: Using `requirements.txt`
```bash
# Create and activate conda environment
conda create --name vnner python=3.10
conda activate vnner

# Install dependencies
pip install -r requirements.txt
```

### Option 2: Using `environment.yml`
```bash
# Create environment from yml file
conda env create -f environment.yml
conda activate vnner
```

## ğŸš€ Quick Start

### Training the Model
```bash
python run.py
```

### Running the Streamlit App
```bash
python src/app.py
```

## ğŸ§ª Experimental Approaches

The project explores multiple methodologies:

1. **PhoBERT + CRF**: Sequential labeling with contextual embeddings
2. **PhoBERT + Softmax**: Direct classification approach
3. **Random Forest + Rule-based**: Traditional ML with linguistic rules
4. **Random Forest + Semantic Embeddings**: Enhanced feature engineering

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is open source. Please check the repository for license details.

## ğŸ™ Acknowledgments

- VLSP2016 dataset providers
- PhoBERT model creators
- Hugging Face for hosting the demo

## ğŸ“š Additional Resources

For better understanding of the project structure and technologies used:

- [Understanding `__init__.py`](https://zetcode.com/python/init-file/)
- [Markdown Basic Syntax](https://www.markdownguide.org/basic-syntax/#escaping-characters)
- [Requirements.txt vs Environment.yml](https://www.reddit.com/r/learnpython/comments/xvlpdz/why_do_people_provide_a_requirementstxt_or/)

---

**Happy NER-ing! ğŸ¯**
