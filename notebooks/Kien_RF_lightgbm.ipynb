{
 "cells": [
  {
   "cell_type": "code",
   "id": "10ec017cb658e125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:21:33.244538Z",
     "start_time": "2025-06-11T00:21:05.317283Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-b0417886a268b83a.parquet', 'valid': 'data/valid-00000-of-00001-846411c236133ba3.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/datnth1709/VLSP2016-NER-data/\" + splits[\"train\"])\n",
    "df_valid = pd.read_parquet(\"hf://datasets/datnth1709/VLSP2016-NER-data/\" + splits[\"valid\"])\n",
    "df = pd.concat([df_train, df_valid]).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c533c55a2ad7b16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:21:33.499341Z",
     "start_time": "2025-06-11T00:21:33.262933Z"
    }
   },
   "source": [
    "# Tạo thêm các cột khác\n",
    "def join_tokens(tokens):\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "def reform_raw_text(tokens):\n",
    "    text = ' '.join(tokens)\n",
    "    return text.replace(\"_\", \" \")\n",
    "\n",
    "def label(x):\n",
    "  return [id_tag[int(i)] for i in x]\n",
    "\n",
    "def replace_7_8(lst):\n",
    "    return [0 if x in (7, 8) else x for x in lst]\n",
    "\n",
    "\n",
    "tag_id = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n",
    "id_tag = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n",
    "\n",
    "\n",
    "df['ner_tags'] = df['ner_tags'].apply(replace_7_8)\n",
    "df['text_withseg'] = df['tokens'].apply(join_tokens)\n",
    "df['text_raw'] = df['tokens'].apply(reform_raw_text)\n",
    "df[\"ner_labels\"] = df.ner_tags.apply(label)\n",
    "df.columns = ['tokens', 'id', 'seg_text', 'raw_text', 'labels']\n",
    "df\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  tokens  \\\n",
       "0                        [Không_khí, thật, náo_nhiệt, .]   \n",
       "1      [Chị, Lãnh, và, Xăng, ra, đi, ,, mình, đứng, n...   \n",
       "2      [Suy_tính, mãi, ,, khóc, mãi, rồi, Phúc, lấy, ...   \n",
       "3      [Hoà, bảo, hồi, mới, qua, đâu, có, biết, nấu_n...   \n",
       "4                         [Nhật_ký, của, thuyền_viên, .]   \n",
       "...                                                  ...   \n",
       "16853  [Nghe, thấy, đã, ghê_ghê, nhưng, Nhiêu, chưa, ...   \n",
       "16854        [Nhưng, mọi, chuyện, không, dừng, ở, đó, .]   \n",
       "16855  [Hoà, bảo, thời_gian, đầu, mặc_cảm, lắm, ,, ở,...   \n",
       "16856  [Biết_bao, người, đã, tình_nguyện, hiến_dâng, ...   \n",
       "16857  [Trên, đây, mới, là, “, thành_tích, ”, tiêu, t...   \n",
       "\n",
       "                                                      id  \\\n",
       "0                                           [0, 0, 0, 0]   \n",
       "1      [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, ...   \n",
       "4                                           [0, 0, 0, 0]   \n",
       "...                                                  ...   \n",
       "16853  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "16854                           [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "16855  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "16856      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "16857  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                seg_text  \\\n",
       "0                             Không_khí thật náo_nhiệt .   \n",
       "1      Chị Lãnh và Xăng ra đi , mình đứng nhìn hai ch...   \n",
       "2      Suy_tính mãi , khóc mãi rồi Phúc lấy ra tờ giấ...   \n",
       "3      Hoà bảo hồi mới qua đâu có biết nấu_nướng gì ,...   \n",
       "4                              Nhật_ký của thuyền_viên .   \n",
       "...                                                  ...   \n",
       "16853  Nghe thấy đã ghê_ghê nhưng Nhiêu chưa được tườ...   \n",
       "16854                 Nhưng mọi chuyện không dừng ở đó .   \n",
       "16855  Hoà bảo thời_gian đầu mặc_cảm lắm , ở trong nh...   \n",
       "16856  Biết_bao người đã tình_nguyện hiến_dâng cả cuộ...   \n",
       "16857  Trên đây mới là “ thành_tích ” tiêu tiền của m...   \n",
       "\n",
       "                                                raw_text  \\\n",
       "0                             Không khí thật náo nhiệt .   \n",
       "1      Chị Lãnh và Xăng ra đi , mình đứng nhìn hai ch...   \n",
       "2      Suy tính mãi , khóc mãi rồi Phúc lấy ra tờ giấ...   \n",
       "3      Hoà bảo hồi mới qua đâu có biết nấu nướng gì ,...   \n",
       "4                              Nhật ký của thuyền viên .   \n",
       "...                                                  ...   \n",
       "16853  Nghe thấy đã ghê ghê nhưng Nhiêu chưa được tườ...   \n",
       "16854                 Nhưng mọi chuyện không dừng ở đó .   \n",
       "16855  Hoà bảo thời gian đầu mặc cảm lắm , ở trong nh...   \n",
       "16856  Biết bao người đã tình nguyện hiến dâng cả cuộ...   \n",
       "16857  Trên đây mới là “ thành tích ” tiêu tiền của m...   \n",
       "\n",
       "                                                  labels  \n",
       "0                                           [O, O, O, O]  \n",
       "1      [O, B-PER, O, B-PER, O, O, O, O, O, O, O, O, O...  \n",
       "2      [O, O, O, O, O, O, B-PER, O, O, O, O, O, O, O,...  \n",
       "3      [B-PER, O, O, O, O, O, O, O, O, O, O, O, O, B-...  \n",
       "4                                           [O, O, O, O]  \n",
       "...                                                  ...  \n",
       "16853  [O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...  \n",
       "16854                           [O, O, O, O, O, O, O, O]  \n",
       "16855  [B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...  \n",
       "16856      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "16857  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "\n",
       "[16858 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>id</th>\n",
       "      <th>seg_text</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Không_khí, thật, náo_nhiệt, .]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>Không_khí thật náo_nhiệt .</td>\n",
       "      <td>Không khí thật náo nhiệt .</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Chị, Lãnh, và, Xăng, ra, đi, ,, mình, đứng, n...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Chị Lãnh và Xăng ra đi , mình đứng nhìn hai ch...</td>\n",
       "      <td>Chị Lãnh và Xăng ra đi , mình đứng nhìn hai ch...</td>\n",
       "      <td>[O, B-PER, O, B-PER, O, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Suy_tính, mãi, ,, khóc, mãi, rồi, Phúc, lấy, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Suy_tính mãi , khóc mãi rồi Phúc lấy ra tờ giấ...</td>\n",
       "      <td>Suy tính mãi , khóc mãi rồi Phúc lấy ra tờ giấ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-PER, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hoà, bảo, hồi, mới, qua, đâu, có, biết, nấu_n...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, ...</td>\n",
       "      <td>Hoà bảo hồi mới qua đâu có biết nấu_nướng gì ,...</td>\n",
       "      <td>Hoà bảo hồi mới qua đâu có biết nấu nướng gì ,...</td>\n",
       "      <td>[B-PER, O, O, O, O, O, O, O, O, O, O, O, O, B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Nhật_ký, của, thuyền_viên, .]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>Nhật_ký của thuyền_viên .</td>\n",
       "      <td>Nhật ký của thuyền viên .</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16853</th>\n",
       "      <td>[Nghe, thấy, đã, ghê_ghê, nhưng, Nhiêu, chưa, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>Nghe thấy đã ghê_ghê nhưng Nhiêu chưa được tườ...</td>\n",
       "      <td>Nghe thấy đã ghê ghê nhưng Nhiêu chưa được tườ...</td>\n",
       "      <td>[O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16854</th>\n",
       "      <td>[Nhưng, mọi, chuyện, không, dừng, ở, đó, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Nhưng mọi chuyện không dừng ở đó .</td>\n",
       "      <td>Nhưng mọi chuyện không dừng ở đó .</td>\n",
       "      <td>[O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16855</th>\n",
       "      <td>[Hoà, bảo, thời_gian, đầu, mặc_cảm, lắm, ,, ở,...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Hoà bảo thời_gian đầu mặc_cảm lắm , ở trong nh...</td>\n",
       "      <td>Hoà bảo thời gian đầu mặc cảm lắm , ở trong nh...</td>\n",
       "      <td>[B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16856</th>\n",
       "      <td>[Biết_bao, người, đã, tình_nguyện, hiến_dâng, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Biết_bao người đã tình_nguyện hiến_dâng cả cuộ...</td>\n",
       "      <td>Biết bao người đã tình nguyện hiến dâng cả cuộ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16857</th>\n",
       "      <td>[Trên, đây, mới, là, “, thành_tích, ”, tiêu, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Trên đây mới là “ thành_tích ” tiêu tiền của m...</td>\n",
       "      <td>Trên đây mới là “ thành tích ” tiêu tiền của m...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16858 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "14d9b9fae58b7173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:21:59.373985Z",
     "start_time": "2025-06-11T00:21:34.524025Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load PhoBERT tokenizer và model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a47ec382649c3036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:23:23.888583Z",
     "start_time": "2025-06-11T00:23:23.885204Z"
    }
   },
   "source": [
    "# Hàm gộp các embedding vectors của token bị tách ra khi qua SentencePiece\n",
    "def group_embeddings(tokens, embeddings):\n",
    "    word_embeddings = []\n",
    "    current_vecs = []\n",
    "\n",
    "    for token, emb in zip(tokens, embeddings):\n",
    "        if token in [\"<s>\", \"</s>\"]:\n",
    "            continue\n",
    "\n",
    "        if token.endswith(\"@@\"):\n",
    "            current_vecs.append(emb)\n",
    "        else:\n",
    "            current_vecs.append(emb)\n",
    "            word_emb = torch.mean(torch.stack(current_vecs), dim=0)\n",
    "            word_embeddings.append(word_emb)\n",
    "            current_vecs = []\n",
    "\n",
    "    if current_vecs:  # Trong trường hợp sót lại cuối câu\n",
    "        word_emb = torch.mean(torch.stack(current_vecs), dim=0)\n",
    "        word_embeddings.append(word_emb)\n",
    "\n",
    "    return word_embeddings"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f8c0ad89ae81b0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:25:52.567135Z",
     "start_time": "2025-06-11T00:23:56.155322Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "all_embeddings = []  # list of [seq_len_i, 768] tensors\n",
    "all_labels = [] # list of [seq_len_i,] tensors\n",
    "len_em = []\n",
    "\n",
    "# count = 0\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    # count += 1\n",
    "    # if count == 500:\n",
    "    #   break\n",
    "\n",
    "    # Truy cập phần tử từng dòng\n",
    "    sentence = row['seg_text']\n",
    "    gold_labels = row[\"id\"]\n",
    "\n",
    "    # Cho sentence đi qua SentencePiece\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].to(device))\n",
    "\n",
    "    # Encode tạo embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "    # Gộp các embeddings đã bị tách khi đi qua SentencePiece\n",
    "    word_embeds = group_embeddings(tokens, last_hidden_state)\n",
    "\n",
    "    # Kiểm tra số lượng embeddings và số lượng labels\n",
    "    if len(word_embeds) != len(gold_labels):\n",
    "        continue\n",
    "\n",
    "    # Thêm vào list tổng / Tới đây là data đã sẵn sàng cho training\n",
    "    all_embeddings.append(torch.stack(word_embeds))\n",
    "    all_labels.append(torch.tensor(gold_labels))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:35:23.255306Z",
     "start_time": "2025-06-11T00:35:23.252026Z"
    }
   },
   "cell_type": "code",
   "source": "# We skip 43 data since they aren't convertable",
   "id": "c3e406ad994802be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-43\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "cadc3a861025b3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:36:18.857012Z",
     "start_time": "2025-06-11T00:36:08.257408Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_flat = []\n",
    "y_flat = []\n",
    "\n",
    "for emb_seq, label_seq in zip(all_embeddings, all_labels):\n",
    "    for emb, label in zip(emb_seq, label_seq):\n",
    "        X_flat.append(emb.cpu().numpy())   # emb: [768]\n",
    "        y_flat.append(label.item())  # label: int\n",
    "\n",
    "X_flat = np.array(X_flat)  # [N, 768]\n",
    "y_flat = np.array(y_flat)  # [N]\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "52a0fe72a50d4f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:39:58.211159Z",
     "start_time": "2025-06-11T00:39:58.208074Z"
    }
   },
   "source": [
    "print(X_flat[0].shape)\n",
    "print(y_flat.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "(368172,)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "d6275df555f0c4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:42:00.129778Z",
     "start_time": "2025-06-11T00:42:00.096986Z"
    }
   },
   "source": [
    "# Kiểm tra độ lệch data\n",
    "unique_values, counts = np.unique(y_flat, return_counts=True)\n",
    "\n",
    "# In ra từng giá trị và số lần xuất hiện\n",
    "for val, count in zip(unique_values, counts):\n",
    "    print(f\"Label {val}: {count} times\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 344986 times\n",
      "Label 1: 7450 times\n",
      "Label 2: 3504 times\n",
      "Label 3: 1204 times\n",
      "Label 4: 2050 times\n",
      "Label 5: 6211 times\n",
      "Label 6: 2767 times\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "664020977ba9a1e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:42:03.350616Z",
     "start_time": "2025-06-11T00:42:02.915680Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_flat, y_flat, test_size=0.2, random_state=42, stratify=y_flat)\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "d4acda9c7cae3214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:42:25.235471Z",
     "start_time": "2025-06-11T00:42:16.769480Z"
    }
   },
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "# Tạo Dataset cho LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Cấu hình tham số LightGBM (Random Forest mode)\n",
    "params = {\n",
    "    \"objective\": \"multiclass\",          # nếu multiclass classification\n",
    "    \"num_class\": len(np.unique(y_train)),\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"boosting_type\": \"rf\",              # random forest mode trong LightGBM\n",
    "    \"num_leaves\": 31,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"is_unbalance\": True\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Train model, tích hợp wandb callback để log metrics\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=2,\n",
    "    valid_sets=[train_data, test_data],\n",
    "    valid_names=[\"train\", \"test\"]\n",
    ")\n",
    "\n",
    "# Dự đoán trên test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Ánh xạ số về nhãn tên entity\n",
    "label_map = {\n",
    "    0: 'O',\n",
    "    1: 'B-PER',\n",
    "    2: 'I-PER',\n",
    "    3: 'B-ORG',\n",
    "    4: 'I-ORG',\n",
    "    5: 'B-LOC',\n",
    "    6: 'I-LOC'\n",
    "}\n",
    "\n",
    "# Chuyển y_test và y_pred sang nhãn gốc\n",
    "y_test_labels = [label_map[i] for i in y_test]\n",
    "y_pred_labels = [label_map[i] for i in y_pred]\n",
    "\n",
    "# In classification report với nhãn thật\n",
    "print(\"\\nClassification Report (theo label gốc):\")\n",
    "print(classification_report(y_test_labels, y_pred_labels, digits=4))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (theo label gốc):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC     0.3679    0.5000    0.4239      1242\n",
      "       B-ORG     0.2639    0.3942    0.3161       241\n",
      "       B-PER     0.4395    0.7490    0.5540      1490\n",
      "       I-LOC     0.2321    0.4448    0.3050       553\n",
      "       I-ORG     0.1532    0.2878    0.2000       410\n",
      "       I-PER     0.4304    0.5863    0.4964       701\n",
      "           O     0.9869    0.9478    0.9669     68998\n",
      "\n",
      "    accuracy                         0.9235     73635\n",
      "   macro avg     0.4106    0.5586    0.4660     73635\n",
      "weighted avg     0.9474    0.9235    0.9336     73635\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:45:00.649942Z",
     "start_time": "2025-06-11T00:45:00.646595Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.feature_importance().shape)",
   "id": "b1cf76bc3e58bc93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:52:36.844604Z",
     "start_time": "2025-06-11T00:52:36.827018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "for i in range(73635):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        correct += 1\n",
    "correct"
   ],
   "id": "39d391e67a51211c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68001"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:57:45.109129Z",
     "start_time": "2025-06-11T00:57:45.105078Z"
    }
   },
   "cell_type": "code",
   "source": "print(y_test.shape)",
   "id": "1a0ba8f0410c5589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73635,)\n"
     ]
    }
   ],
   "execution_count": 61
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
